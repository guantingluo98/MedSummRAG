{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/py310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "import json\n",
    "from transformers import AdamW\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "import argparse\n",
    "from datasets import Dataset, DatasetDict\n",
    "from datasets import load_dataset\n",
    "\n",
    "import torch\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDatalist(jsonPath):\n",
    "    data_list = []\n",
    "    with open(jsonPath, 'r') as input:\n",
    "        for jsonObj in input:\n",
    "            testObj = jsonObj.strip()\n",
    "            data_list.append(json.loads(testObj))\n",
    "        input.close()\n",
    "    return data_list\n",
    "\n",
    "def getDataWithPrompt(datalist):\n",
    "    res = []\n",
    "    system_msg = \"You are a helpful assistant. Your task is to summarize the given question based on the provided question and possibly helpful retrieved documents. The retrieved documents may or may not be useful for summarization.\"\n",
    "    for i in range(len(datalist)):  \n",
    "        question = datalist[i][\"question\"]\n",
    "        summary = datalist[i][\"summary\"]\n",
    "        retrieval_doc = datalist[i][\"retrieval\"][0][\"doc\"]\n",
    "        input_text = f\"{question.strip()}\\n### Retrieved Document:\\n{retrieval_doc}\"\n",
    "        res.append({\"instruction\":\"\", \"input\": input_text, \"output\": summary.strip()})\n",
    "    return res\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = examples[\"input_text\"]\n",
    "    targets = examples[\"target\"]\n",
    "    model_inputs = tokenizer(inputs, max_length=1024, truncation=True, padding=\"max_length\")\n",
    "    labels = tokenizer(targets, max_length=50, truncation=True, padding=\"max_length\")\n",
    "    return {\n",
    "        \"input_ids\": model_inputs[\"input_ids\"],\n",
    "        \"attention_mask\": model_inputs[\"attention_mask\"],\n",
    "        \"labels\": labels[\"input_ids\"],\n",
    "    }\n",
    "\n",
    "\n",
    "def formatting_prompts_func(examples):\n",
    "    instructions = examples[\"instruction\"]\n",
    "    inputs       = examples[\"input\"]\n",
    "    outputs      = examples[\"output\"]\n",
    "    texts = []\n",
    "    for instruction, input, output in zip(instructions, inputs, outputs):\n",
    "\n",
    "        text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return { \"text\" : texts, }\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.3.9: Fast Qwen2 patching. Transformers: 4.49.0.\n",
      "   \\\\   /|    NVIDIA RTX A6000. Num GPUs = 2. Max memory: 47.544 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.4.0+cu121. CUDA: 8.6. CUDA Toolkit: 12.1. Triton: 3.0.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.27.post2. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.01it/s]\n",
      "Unsloth 2025.3.9 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "max_seq_length = 2048 \n",
    "dtype = None \n",
    "load_in_4bit = True \n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Qwen2.5-7B\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "   \n",
    ")\n",
    "EOS_TOKEN = tokenizer.eos_token \n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 8, \n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0, \n",
    "    bias = \"none\",\n",
    "    use_gradient_checkpointing = \"unsloth\",\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  \n",
    "    loftq_config = None, \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "alpaca_prompt = \"\"\"You are a helpful assistant. Your task is to summarize the given question based on the provided question and possibly helpful retrieved documents. The retrieved documents may or may not be useful for summarization.\n",
    "{}\n",
    "### Question:\n",
    "{}\n",
    "### Summary:\n",
    "{}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:00<00:00, 78801.79 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': '', 'input': \"anyone know any cures or treatments for a crick in your neck???? ive tried everything - heating pads, ice packs (which i wasn't supposed to use), i tried the thing that stimulates my nerves, but the battery didn't work, those things you heat up in the microwave, Advil, and a prescribed medicine thing - i'm in so much pain!!!!!!! and i'm looking for serious answers!!\\n### Retrieved Document:\\nWhat are the causes and remedies for the Neck pain?   answer: Causes: stress is #1 in my book, next to injury. I suffer from neck pain from sitting at the computer for long periods of time. Cramps that come from sleeping in a bad position at night can pinch your nerves and cause discomfort.\\n\\nRemedies: I bought a neck messaging chair for about $100. It does great for short-term relief, but for the long-term, it sucks. Heating pads help to calm the nerves in the neck, as well as massage. Sometimes, depending on the source of your pain, Tylenol-type products will help.\", 'output': 'What is the best way to get rid of a crick in your neck?', 'text': \"You are a helpful assistant. Your task is to summarize the given question based on the provided question and possibly helpful retrieved documents. The retrieved documents may or may not be useful for summarization.\\n\\n### Question:\\nanyone know any cures or treatments for a crick in your neck???? ive tried everything - heating pads, ice packs (which i wasn't supposed to use), i tried the thing that stimulates my nerves, but the battery didn't work, those things you heat up in the microwave, Advil, and a prescribed medicine thing - i'm in so much pain!!!!!!! and i'm looking for serious answers!!\\n### Retrieved Document:\\nWhat are the causes and remedies for the Neck pain?   answer: Causes: stress is #1 in my book, next to injury. I suffer from neck pain from sitting at the computer for long periods of time. Cramps that come from sleeping in a bad position at night can pinch your nerves and cause discomfort.\\n\\nRemedies: I bought a neck messaging chair for about $100. It does great for short-term relief, but for the long-term, it sucks. Heating pads help to calm the nerves in the neck, as well as massage. Sometimes, depending on the source of your pain, Tylenol-type products will help.\\n### Summary:\\nWhat is the best way to get rid of a crick in your neck?<|endoftext|>\"}\n",
      "Dataset({\n",
      "    features: ['instruction', 'input', 'output', 'text'],\n",
      "    num_rows: 1000\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data_ = getDatalist(\"/data/luo/hqs/yahoo_lg/train_rerank_seed4396.json\")\n",
    "val_data_ = getDatalist(\"/data/luo/hqs/yahoo_lg/test_rerank_seed4396.json\")\n",
    "train_data = getDataWithPrompt(train_data_)\n",
    "val_data = getDataWithPrompt(val_data_)\n",
    "dataset__ = DatasetDict({\n",
    "    \"train\": Dataset.from_list(train_data),\n",
    "    \"validation\": Dataset.from_list(val_data)\n",
    "})\n",
    "dataset = dataset__[\"train\"].map(formatting_prompts_func, batched = True,)\n",
    "print(dataset[0])\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ = load_dataset(\"yahma/alpaca-cleaned\", split = \"train\")\n",
    "dataset = dataset_.map(formatting_prompts_func, batched = True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing to [\"text\"] (num_proc=2): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:01<00:00, 561.05 examples/s]\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 1,000 | Num Epochs = 10 | Total steps = 310\n",
      "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 4 x 1) = 32\n",
      " \"-____-\"     Trainable parameters = 20,185,088/5,042,935,296 (0.40% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='106' max='310' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [106/310 19:28 < 38:12, 0.09 it/s, Epoch 3.29/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.388300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.454900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.433600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.450500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.298600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.224700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.149300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.037300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.095000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.077200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.066400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.045900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.042100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.107900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.961200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.965400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.017300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.025300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.023200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2.043300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.983100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>2.044900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.987100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.983900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.940400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.858000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>2.004400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.944600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.987300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>1.935200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.992200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>2.009300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.955000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.937200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.961000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.915400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.894400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.999400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.912200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.987600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.973300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>1.978200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.833800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.904900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.994400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>1.950300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>2.024800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1.976300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.003700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>1.948300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.893500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>1.948100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>1.964200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.986500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>1.914100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>1.951300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>1.877200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>2.029400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.834400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>1.867700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>1.983800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>1.955800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>2.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>1.882500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>1.830300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>1.932800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>1.899600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>1.899700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>1.823200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>1.884500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>1.909800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>1.858300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.868600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>1.870500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>1.907600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>1.884900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>1.837200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.942800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>1.875700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>1.815100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>1.848300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>1.934300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>1.833000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>1.925800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>1.870400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>1.824700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>1.860500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.815400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>1.850900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>1.906000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>1.876900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>1.814600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>2.021500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>1.709000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>1.851400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>1.814700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>1.822400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.733600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>1.720800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>1.823400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>1.833700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>1.748300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False,\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 4,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        warmup_steps = 5,\n",
    "        num_train_epochs = 10,\n",
    "        learning_rate = 2e-4,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 1,\n",
    "        output_dir = \"outputs\",\n",
    "        report_to = \"none\", # Use this for WandB etc\n",
    "    ),\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "trainer_stats = trainer.train()\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Training completed in {elapsed_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['You are a helpful assistant. Your task is to summarize the given question based on the provided question and possibly helpful retrieved documents. The retrieved documents may or may not be useful for summarization.\\n\\n### Question:\\nHow do I get rid of pain in my back after soccer? I am 25 and is it normal to have back pain every time after I play soccer? Help me, am I doing anything wrong and what can I do to make the pain go away?\\n### Retrieved Document:\\nRight Lower Back Pain HELP!!? I have lower back pain problems that just started about a week ago. If i lay on my back and lift my left leg it doesnt hurt, but when i lift my right leg my right lower back hurts. The worst part is that i play soccer and kick with my right foot so i have to lift it and it REALLY hurts. I need to know some exercises and why it hurts and what i should do PLEASE!!  answer: Acute back pain is treated with muscle relaxantsor nonsteroidal anti-inflammatory drugs (NSAIDs), such as ibuprofen or aspirin. Applications of compresses using heat or cold also can be helpful to some patients.\\n### Summary:\\nHow to treat and prevent back pain after playing soccer?<|endoftext|>']\n"
     ]
    }
   ],
   "source": [
    "FastLanguageModel.for_inference(model)\n",
    "input_text = alpaca_prompt.format(\n",
    "        dataset[3][\"instruction\"],\n",
    "        dataset[3][\"input\"],\n",
    "        \"\",\n",
    "    )\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    input_text\n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens = 50, use_cache = True)\n",
    "print(tokenizer.batch_decode(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "FastLanguageModel.for_inference(model)\n",
    "def getOutputs(model, tokenizer, dataset, savepath):\n",
    "    pattern = r\"### Summary:\\n(.*?)(<\\|endoftext\\|>|$)\"\n",
    "    res = []\n",
    "    for i in range(len(dataset)):\n",
    "        input_text = alpaca_prompt.format(\n",
    "            dataset[i][\"instruction\"],\n",
    "            dataset[i][\"input\"]\n",
    "            \"\",\n",
    "        )\n",
    "        inputs = tokenizer(input_text, return_tensors = \"pt\").to(\"cuda\")\n",
    "        \n",
    "        outputs = model.generate(**inputs, max_new_tokens = 80, use_cache = True)\n",
    "        text = tokenizer.batch_decode(outputs)[0]\n",
    "        #print(text)\n",
    "        match = re.search(pattern, text)\n",
    "        if match:\n",
    "            summary = match.group(1).strip()\n",
    "            res.append(summary)\n",
    "        if \"endoftext\" not in text:\n",
    "            print(i)\n",
    "            print(text)\n",
    "    with open(savepath, \"w\", encoding=\"utf-8\") as file:\n",
    "        for string in res:\n",
    "            file.write(string + \"\\n\")\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334\n",
      "You are a helpful assistant. Your task is to summarize the given question based on the provided question and possibly helpful retrieved documents. The retrieved documents may or may not be useful for summarization.\n",
      "\n",
      "### Question:\n",
      "I'm concerned much? what's my risk of contracting the HIV/AIDS virus if I've never had vaginal or anal sex, never performed oral sex, never shared needles or had tattoos, never had blood transfusions, never had needlestick lacerations, never shared sex toys, but received unprotected oral sex a few times, engaged in deep French kissing, was fingered, and I had no underwear on, and I sat on a man's penis(which was covered by his underwear), and his underwear was wet from his semen, and also got some semen on my finger, wiped it off on the guy's shirt,(I didn't look when I wiped it off on his shirt), and then, a few seconds later, with that same finger, touched my labia minora, and lastly, I touched his penis(which seemed moist), then touched a one-day-old open cut on my lower lip? Is it high risk, low risk, or no risk? thanks. lastly, what do you mean by theoretical risk? is it the same as likelihood? please let me know, for I'm very worried, and this guilt about what I did is killing me.\n",
      "### Retrieved Document:\n",
      "What is the real % of possibilities of getting aids from oral sex in case there are no obvious wounds ?   answer: The risk of becoming infected with HIV through unprotected (without a condom) oral sex is lower than that of unprotected anal or vaginal sex. However, a lower-risk activity will increase in risk when it is done often enough. The Options Project found that 7.8% (8 of 102) of recently infected men who have sex with men in San Francisco were probably infected through oral sex. Nearly half (3 of 8) of these cases reported oral problems, including occasional bleeding gums. Almost all (7 of 8) of these men reported to have had oral contact with pre-semen or semen.\n",
      "\n",
      "The risk of oral sex transmission (8%) in this study is higher than many researchers had previously thought or found in other studies. More media attention appeared to be placed on this particular study, probably because of the higher number of study participants. There appears to be evidence that higher-risk activities (anal sex) among men who have sex with men is decreasing while lower-risk activities (oral sex) among these men is increasing. Oral sex has always been considered a lower-risk activity but is certainly not risk free.\n",
      "### Summary:\n",
      "What is the risk of contracting HIV/AIDS if I've never had vaginal or anal sex, never performed oral sex, never shared needles or had tattoos, never had blood transfusions, never had needlestick lacerations, never shared sex toys, received unprotected oral sex a few times, engaged in deep French kissing, was fingered, and I had no underwear on, and I sat on a man\n"
     ]
    }
   ],
   "source": [
    "results = getOutputs(model, tokenizer, test_dataset, \"savePath\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| ROUGE-1 | ROUGE-2 | ROUGE-L |\n",
      "|---------|---------|---------|\n",
      "|   42.95  |   22.82  |   40.03  |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "targets_path = \".../CHQ-Summ/test.target\"\n",
    "save_path = \"save_path\"\n",
    "print(rouge155.calculate_rouge155_md(targets_path, save_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
