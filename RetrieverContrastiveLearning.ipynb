{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence embeddings: tensor([[-0.0401, -0.0034, -0.0373,  ..., -0.0112, -0.0444,  0.0459],\n",
      "        [-0.0226,  0.0141, -0.0487,  ..., -0.0215, -0.0595,  0.0210]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import os\n",
    "from info_nce import InfoNCE, info_nce\n",
    "model_name = 'BAAI/bge-m3'\n",
    "BATCH_SIZE=1\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "def worker_init_fn(worker_id):\n",
    "    seed = 42 + worker_id\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "model.eval()\n",
    "device=\"cuda\"\n",
    "model.to(device)\n",
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "encoded_input.to(device)\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "    sentence_embeddings = model_output[0][:, 0]\n",
    "sentence_embeddings = torch.nn.functional.normalize(sentence_embeddings, p=2, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSim(q,p,tokenizer,model):\n",
    "    encoded_input = tokenizer([q,p], padding=True, truncation=True, return_tensors='pt')\n",
    "    encoded_input.to(device)\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "        sentence_embeddings = model_output[0][:, 0]\n",
    "    sentence_embeddings = torch.nn.functional.normalize(sentence_embeddings, p=2, dim=1)\n",
    "    q_embeddings=sentence_embeddings[0]\n",
    "    p_embeddings=sentence_embeddings[1]\n",
    "    scores = q_embeddings @ p_embeddings.T\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121 106 120\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(4396)\n",
    "random_int1 = random.randint(100, 149)\n",
    "random_int2 = random.randint(100, 149)\n",
    "random_int3 = random.randint(100, 149)\n",
    "print(random_int1, random_int2, random_int3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1,\n",
       " 'question': 'who makes bromocriptine\\ni am wondering what company makes the drug bromocriptine, i need it for a mass i have on my pituitary gland and the cost just keeps raising. i cannot ever buy a full prescription because of the price and i was told if i get a hold of the maker of the drug sometimes they offer coupons or something to help me afford the medicine. if i buy 10 pills in which i have to take 2 times a day it costs me 78.00. and that is how i have to buy them.  thanks.',\n",
       " 'negative': [\"SUBJECT: My humerus bone\\nMESSAGE: Hello. My name is [NAME], I am 33 years old, from Romania in Europe and I have a 6 inches difference between my left humerus bone and my right one. It all started when I was around 4 years old and I had a bone illness called: bone cyst. First it affected my right femur and then my left shoulder. The bones were very fragile in the mentioned areas and I had fractured them many times very easily. I had 3 surgeries at my shoulder and I healed up after a bone transplant from my hip and after some hydrocortisone injections. All good but as I said my left humerus bone is a lot shorter. The doctors said that my growth plate was affected that's why it is this difference between my hands. It bothers me a lot, especially when I'm in sports (bodybuilding, basketball), and I would like to know if there is something that can be done for me to make things right. Any suggestions are welcome, but just don't tell me to give up. Hoping for a soon answer, I thank you.  answer: What are treatments for differences in arm length,  and how can I find physician(s) or hospital(s) who specialize in it in Romania?\",\n",
       "  \"SUBJECT: Low Platelet Count\\nMESSAGE: hello i am facing low platelet count in my blood (PTI) and am taking the therapy (1 Pill Prednisone 2mg Morning - Myfortic 2 Pills Morning - 2 Pills Night) i want to ask [NAME] MD, Professor of Medicine if removing the spleen will cause anything or if there any side effects when removing it. and what is the cause of this (PTI) been in this 4 months and my platelet count are (70 000 - 140 000 - 65 000 - 90 000) didn't reach the normal count. is this therapy good and will it help? i just need some answers please. waiting to hear from you soon sincerely, [NAME]  answer: What are the causes and best treatments for low platelet counts?\",\n",
       "  \"MESSAGE: I am 22 weeks pregnant and just found out my son has Transposition Of The Great Arteries &will have to have surgery a few days after birth.When reading your section on this it mentions may have other birth defects,what would those be? Also i was wondering out of the surgery's listed how severe is this one in comparison to the others?Thanks for your time and i am anxiously waiting on your reply.Sincerely, [NAME]  answer: What birth defects co-occur with Transposition Of The Great Arteries  and how dangerous is the surgery to corect it in a newborn? \"],\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "import random\n",
    "def getDatalist(jsonPath):\n",
    "    data_list = []\n",
    "    with open(jsonPath, 'r') as input:\n",
    "        for jsonObj in input:\n",
    "            testObj = jsonObj.strip()\n",
    "            data_list.append(json.loads(testObj))\n",
    "        input.close()\n",
    "    return data_list\n",
    "train_neg_path=\"negetive_documents\"\n",
    "train_neg_json=getDatalist(train_neg_path)\n",
    "train_pos_path=\"fake_positive_documents\"\n",
    "train_pos_json=getDatalist(train_pos_path)\n",
    "\n",
    "def getNegPairs(datalist, idx):\n",
    "    res=[]\n",
    "    for i, item in enumerate(datalist):\n",
    "        res.append({\n",
    "            \"id\":i,\n",
    "            \"question\": item[\"question\"],\n",
    "            \"negative\": [item[\"retrieval\"][idx][\"doc\"],item[\"retrieval\"][idx+1][\"doc\"],item[\"retrieval\"][idx+2][\"doc\"]],\n",
    "            \"label\": 0\n",
    "        })\n",
    "    return res\n",
    "\n",
    "def getRandomNegPairs(datalist):\n",
    "    random.seed(4396)\n",
    "    random_int1 = random.randint(100, 149)\n",
    "    random_int2 = random.randint(100, 149)\n",
    "    random_int3 = random.randint(100, 149)\n",
    "    res=[]\n",
    "    for i, item in enumerate(datalist):\n",
    "        res.append({\n",
    "            \"id\":i,\n",
    "            \"question\": item[\"question\"],\n",
    "            \"negative\": [item[\"retrieval\"][random_int1][\"doc\"],item[\"retrieval\"][random_int2][\"doc\"],item[\"retrieval\"][random_int3][\"doc\"]],\n",
    "            \"label\": 0\n",
    "        })\n",
    "    return res\n",
    "train_negs=getRandomNegPairs(train_neg_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTriTexts(negs, pos):\n",
    "    res=[]\n",
    "    for p in pos:\n",
    "        idx = p[\"id\"]\n",
    "        for n in negs:\n",
    "            if idx==n[\"id\"]:\n",
    "                res.append({\n",
    "                    \"id\":idx,\n",
    "                    \"question\":p[\"question\"],\n",
    "                    \"positive\":p[\"retrieval\"][-1][\"doc\"],\n",
    "                    \"negative\":n[\"negative\"]\n",
    "                })\n",
    "    return res\n",
    "train_set = getTriTexts(train_negs,train_pos_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch: torch.Size([3, 132])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "\n",
    "class ContrastiveDataset(Dataset):\n",
    "    def __init__(self, datalist, tokenizer):\n",
    "        self.datalist=datalist\n",
    "        self.tokenizer=tokenizer\n",
    "    def __len__(self):\n",
    "        return len(self.datalist)\n",
    "    def __getitem__(self, idx):\n",
    "        q_ids=self.tokenizer(self.datalist[idx][\"question\"], padding=True, truncation=True, return_tensors='pt')\n",
    "        p_ids=self.tokenizer(self.datalist[idx][\"positive\"], padding=True, truncation=True, return_tensors='pt')\n",
    "        n_ids=self.tokenizer(self.datalist[idx][\"negative\"], padding=True, truncation=True, return_tensors='pt')\n",
    "        return {\n",
    "            \"q_id\":q_ids,\n",
    "            \"p_id\":p_ids,\n",
    "            \"n_id\":n_ids,\n",
    "            \"question\":self.datalist[idx][\"question\"],\n",
    "            \"positive\":self.datalist[idx][\"positive\"],\n",
    "            \"negative\":self.datalist[idx][\"negative\"],\n",
    "        }\n",
    "def contrastive_collate_fn(batch):\n",
    "    questions = [item['question'] for item in batch]\n",
    "    positives = [item['positive'] for item in batch]\n",
    "    negatives = [item['negative'][0] for item in batch]\n",
    "    q_inputs = [tokenizer(text, truncation=True, padding=False) for text in questions]\n",
    "    p_inputs = [tokenizer(text, truncation=True, padding=False) for text in positives]\n",
    "    n_inputs = [tokenizer(text, truncation=True, padding=False) for text in negatives]\n",
    "    questions_padded = tokenizer.pad(q_inputs, padding=True, return_tensors='pt')\n",
    "    positives_padded = tokenizer.pad(p_inputs, padding=True, return_tensors='pt')\n",
    "    negatives_padded = tokenizer.pad(n_inputs, padding=True, return_tensors='pt')\n",
    "    return {\n",
    "        \"question\": questions_padded,\n",
    "        \"positive\": positives_padded,\n",
    "        \"negative\": negatives_padded,\n",
    "    }\n",
    "def contrastive_collate_fn(batch):\n",
    "    questions = [item['question'] for item in batch]\n",
    "    positives = [item['positive'] for item in batch]\n",
    "    negatives = [item['negative'] for item in batch]\n",
    "    q_inputs = [tokenizer(text, truncation=True, padding=False) for text in questions]\n",
    "    p_inputs = [tokenizer(text, truncation=True, padding=False) for text in positives]\n",
    "    questions_padded = tokenizer.pad(q_inputs, padding=True, return_tensors='pt')\n",
    "    positives_padded = tokenizer.pad(p_inputs, padding=True, return_tensors='pt')\n",
    "    flattened_negatives = [neg for neg_list in negatives for neg in neg_list]\n",
    "    n_inputs = [tokenizer(text, truncation=True, padding=False) for text in flattened_negatives]\n",
    "    negatives_padded = tokenizer.pad(n_inputs, padding=True, return_tensors='pt')\n",
    "    return {\n",
    "        \"question\": questions_padded,\n",
    "        \"positive\": positives_padded,\n",
    "        \"negative\": negatives_padded,\n",
    "    }\n",
    "train_dataset = ContrastiveDataset(train_set, tokenizer)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=contrastive_collate_fn, worker_init_fn=worker_init_fn)\n",
    "first_batch = next(iter(train_dataloader))\n",
    "print(\"First batch:\", first_batch[\"negative\"][\"input_ids\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3373, device='cuda:0')\n",
      "Epoch 1: Loss = 0.008785298461409638\n",
      "tensor(-0.2993, device='cuda:0')\n",
      "Epoch 2: Loss = 1.0914048927588737e-05\n",
      "tensor(-0.3837, device='cuda:0')\n",
      "Epoch 3: Loss = 0.031121241017581156\n",
      "tensor(0.0064, device='cuda:0')\n",
      "Epoch 4: Loss = 0.0006548297641243153\n",
      "tensor(-0.3472, device='cuda:0')\n",
      "Epoch 5: Loss = 2.431024562224593e-05\n",
      "tensor(-0.3818, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(getSim(train_negs[1][\"question\"],train_negs[1][\"negative\"][-1],tokenizer,model))\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
    "infonce_loss = InfoNCE(negative_mode='paired')\n",
    "model.train()\n",
    "batch_losses = []\n",
    "for epoch in range(5):\n",
    "    epoch_losses = [] \n",
    "    for batch in train_dataloader:\n",
    "        q_ids = batch[\"question\"].to(device)\n",
    "        p_ids = batch[\"positive\"].to(device)\n",
    "        n_ids = batch[\"negative\"].to(device)\n",
    "        q_emb = model(**q_ids).last_hidden_state[:, 0, :]\n",
    "        p_emb = model(**p_ids).last_hidden_state[:, 0, :]\n",
    "        n_emb = model(**n_ids).last_hidden_state[:, 0, :]\n",
    "        emb_size = n_emb.shape[-1]\n",
    "        n_emb = n_emb.view(BATCH_SIZE, 3, emb_size)\n",
    "        loss = infonce_loss(q_emb, p_emb, n_emb)\n",
    "        epoch_losses.append(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    batch_losses.extend(epoch_losses)\n",
    "    print(f\"Epoch {epoch+1}: Loss = {sum(epoch_losses) / len(epoch_losses)}\")\n",
    "    print(getSim(train_negs[1][\"question\"],train_negs[1][\"negative\"][-1],tokenizer,model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = getDatalist(\"train_data\")\n",
    "val_data = getDatalist(\"val_data\")\n",
    "test_data = getDatalist(\"test_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSims(q, passages, tokenizer, model, device):\n",
    "    texts = [q] + passages\n",
    "    encoded_input = tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
    "    encoded_input = encoded_input.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "        sentence_embeddings = model_output[0][:, 0]\n",
    "    sentence_embeddings = torch.nn.functional.normalize(sentence_embeddings, p=2, dim=1)\n",
    "\n",
    "    q_embeddings = sentence_embeddings[0]\n",
    "    p_embeddings = sentence_embeddings[1:]\n",
    "    scores = torch.matmul(p_embeddings, q_embeddings.T)\n",
    "\n",
    "    return scores\n",
    "\n",
    "def find_best_passages(data, tokenizer, model, device, top_n):\n",
    "    best_results = []\n",
    "    for item in data:\n",
    "        query = item[\"question\"]\n",
    "        summary = item[\"summary\"]\n",
    "        passages = [p[\"doc\"] for p in item[\"retrieval\"]]\n",
    "        if top_n>0:\n",
    "            passages = passages[:top_n]\n",
    "        scores = getSims(query, passages, tokenizer, model, device)\n",
    "        best_idx = torch.argmax(scores).item()\n",
    "        best_passage = passages[best_idx]\n",
    "        best_score = scores[best_idx].item()\n",
    "        best_results.append({\n",
    "            \"id\": item[\"id\"],\n",
    "            \"question\": query,\n",
    "            \"summary\":summary,\n",
    "            \"retrieval\": [{\"doc\":best_passage,\"score\":best_score}],\n",
    "        })\n",
    "        if len(best_results)%10==0:\n",
    "            print(len(best_results))\n",
    "    return best_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "val_rerank = find_best_passages(val_data, tokenizer, model, device, 20)\n",
    "test_rerank = find_best_passages(test_data, tokenizer, model, device, 20)\n",
    "train_rerank = find_best_passages(train_data, tokenizer, model, device, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def dicts2jsons(dicts, des_path):\n",
    "    with open(des_path, 'w', encoding='utf-8') as file:\n",
    "        for item in dicts:\n",
    "            file.write(json.dumps(item)+\"\\n\")\n",
    "        file.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_json_path=\"train_json_path\"\n",
    "dicts2jsons(train_rerank, train_json_path)\n",
    "test_json_path=\"test_json_path\"\n",
    "dicts2jsons(test_rerank, test_json_path)\n",
    "val_json_path=\"val_json_path\"\n",
    "dicts2jsons(val_rerank, val_json_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
